#!/usr/bin/python

'''
# This script is used to read all json files and convert into csv files containing necessary info
# schema: <userId, time, tweetId:tweet, retweet_userId>
# 
# To run this script:
# Make sure you hava generated csv file list first using "s3cmd ls S3://15619twitter > fileList.csv" first!
#
# REMINDER: please modify me according to the new schema.
#
'''

import re
import sys
import json
import csv
import urllib

# get system parameters
split_fileList = sys.argv[1:]


for split_file in split_fileList:
    # list of file s3 urls of tweet json
    s3_file_list = []

    # fetch csv file generated by s3cmd ls
    csvFile = open(split_file, 'r')

    for line in csvFile:
        m = re.search(r"s3://(.+json)", line)
        s3url = "https://s3.amazonaws.com/" + m.group(1)

        s3_file_list.append(s3url)

    csvFile.close()

    # output csv file
    outputFilename = split_file
    outputFile = open('result_' + outputFilename, "w+")
    outputWriter = csv.writer(outputFile)

    opener = urllib.URLopener()

    # iterate all files
    for s3url in s3_file_list:
        tweet_file = opener.open(s3url)
        localList = list(tweet_file)

        for json_line in localList:
            try:
                decoded_data = json.loads(json_line)
            except ValueError:
                continue

            tweetId = int(decoded_data['id'])
            userId = int(decoded_data['user']['id'])
            originalUserId = -1

            if 'retweeted_status' in decoded_data:
                originalUserId = int(decoded_data['retweeted_status']['user']['id'])

            outputWriter.writerow([tweetId, userId, originalUserId])

        tweet_file.close()
        # open a file to write the result

    outputFile.close()




